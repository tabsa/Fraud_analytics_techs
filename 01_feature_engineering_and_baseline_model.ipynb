{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for the preprocessing and EDA steps\n",
    "Here we progress with the feature engineering and baseline model steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from collections import Counter\n",
    "pd.set_option('display.max_rows', 30)\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facies</th>\n",
       "      <th>Formation</th>\n",
       "      <th>Well Name</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "      <th>FaciesLabels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2793.0</td>\n",
       "      <td>77.45</td>\n",
       "      <td>0.664</td>\n",
       "      <td>9.9</td>\n",
       "      <td>11.915</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>FSiS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2793.5</td>\n",
       "      <td>78.26</td>\n",
       "      <td>0.661</td>\n",
       "      <td>14.2</td>\n",
       "      <td>12.565</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979</td>\n",
       "      <td>FSiS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2794.0</td>\n",
       "      <td>79.05</td>\n",
       "      <td>0.658</td>\n",
       "      <td>14.8</td>\n",
       "      <td>13.050</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957</td>\n",
       "      <td>FSiS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2794.5</td>\n",
       "      <td>86.10</td>\n",
       "      <td>0.655</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.115</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936</td>\n",
       "      <td>FSiS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2795.0</td>\n",
       "      <td>74.58</td>\n",
       "      <td>0.647</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.300</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915</td>\n",
       "      <td>FSiS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Facies Formation  Well Name   Depth     GR  ILD_log10  DeltaPHI   PHIND  \\\n",
       "0       3     A1 SH  SHRIMPLIN  2793.0  77.45      0.664       9.9  11.915   \n",
       "1       3     A1 SH  SHRIMPLIN  2793.5  78.26      0.661      14.2  12.565   \n",
       "2       3     A1 SH  SHRIMPLIN  2794.0  79.05      0.658      14.8  13.050   \n",
       "3       3     A1 SH  SHRIMPLIN  2794.5  86.10      0.655      13.9  13.115   \n",
       "4       3     A1 SH  SHRIMPLIN  2795.0  74.58      0.647      13.5  13.300   \n",
       "\n",
       "    PE  NM_M  RELPOS FaciesLabels  \n",
       "0  4.6     1   1.000         FSiS  \n",
       "1  4.1     1   0.979         FSiS  \n",
       "2  3.6     1   0.957         FSiS  \n",
       "3  3.5     1   0.936         FSiS  \n",
       "4  3.4     1   0.915         FSiS  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read pickle file\n",
    "wok_dir = Path.cwd() / 'datasets/'\n",
    "filename = 'facies_dataset_preprocess.parquet'\n",
    "path_file = wok_dir / filename\n",
    "data = pd.read_parquet(path_file) # Read file\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4149 entries, 0 to 4148\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   Facies        4149 non-null   int64   \n",
      " 1   Formation     4149 non-null   object  \n",
      " 2   Well Name     4149 non-null   category\n",
      " 3   Depth         4149 non-null   float64 \n",
      " 4   GR            4149 non-null   float64 \n",
      " 5   ILD_log10     4149 non-null   float64 \n",
      " 6   DeltaPHI      4149 non-null   float64 \n",
      " 7   PHIND         4149 non-null   float64 \n",
      " 8   PE            4149 non-null   float64 \n",
      " 9   NM_M          4149 non-null   int64   \n",
      " 10  RELPOS        4149 non-null   float64 \n",
      " 11  FaciesLabels  4149 non-null   object  \n",
      "dtypes: category(1), float64(7), int64(2), object(2)\n",
      "memory usage: 361.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check dtype - it matches with preprocessing step\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "First step is always feature extraction from categorical features such as `Formation` that we need to convert to `numerical` feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Facies</th>\n",
       "      <th>Formation</th>\n",
       "      <th>Well Name</th>\n",
       "      <th>Depth</th>\n",
       "      <th>GR</th>\n",
       "      <th>ILD_log10</th>\n",
       "      <th>DeltaPHI</th>\n",
       "      <th>PHIND</th>\n",
       "      <th>PE</th>\n",
       "      <th>NM_M</th>\n",
       "      <th>RELPOS</th>\n",
       "      <th>FaciesLabels</th>\n",
       "      <th>Formation_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2793.0</td>\n",
       "      <td>77.45</td>\n",
       "      <td>0.664</td>\n",
       "      <td>9.9</td>\n",
       "      <td>11.915</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>FSiS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2793.5</td>\n",
       "      <td>78.26</td>\n",
       "      <td>0.661</td>\n",
       "      <td>14.2</td>\n",
       "      <td>12.565</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979</td>\n",
       "      <td>FSiS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2794.0</td>\n",
       "      <td>79.05</td>\n",
       "      <td>0.658</td>\n",
       "      <td>14.8</td>\n",
       "      <td>13.050</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.957</td>\n",
       "      <td>FSiS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2794.5</td>\n",
       "      <td>86.10</td>\n",
       "      <td>0.655</td>\n",
       "      <td>13.9</td>\n",
       "      <td>13.115</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.936</td>\n",
       "      <td>FSiS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>A1 SH</td>\n",
       "      <td>SHRIMPLIN</td>\n",
       "      <td>2795.0</td>\n",
       "      <td>74.58</td>\n",
       "      <td>0.647</td>\n",
       "      <td>13.5</td>\n",
       "      <td>13.300</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915</td>\n",
       "      <td>FSiS</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Facies Formation  Well Name   Depth     GR  ILD_log10  DeltaPHI   PHIND  \\\n",
       "0       3     A1 SH  SHRIMPLIN  2793.0  77.45      0.664       9.9  11.915   \n",
       "1       3     A1 SH  SHRIMPLIN  2793.5  78.26      0.661      14.2  12.565   \n",
       "2       3     A1 SH  SHRIMPLIN  2794.0  79.05      0.658      14.8  13.050   \n",
       "3       3     A1 SH  SHRIMPLIN  2794.5  86.10      0.655      13.9  13.115   \n",
       "4       3     A1 SH  SHRIMPLIN  2795.0  74.58      0.647      13.5  13.300   \n",
       "\n",
       "    PE  NM_M  RELPOS FaciesLabels  Formation_num  \n",
       "0  4.6     1   1.000         FSiS              2  \n",
       "1  4.1     1   0.979         FSiS              2  \n",
       "2  3.6     1   0.957         FSiS              2  \n",
       "3  3.5     1   0.936         FSiS              2  \n",
       "4  3.4     1   0.915         FSiS              2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Formation_num'] = LabelEncoder().fit_transform(data['Formation'].astype(str)) + 1\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a well for testing phase\n",
    "Our model will not see the data from `Well Name == KIMZEY A` during the training process. We use the data from this well as test, the rest it is for tranining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data[data['Well Name'] == 'KIMZEY A']\n",
    "data_fe = data[data['Well Name'] != 'KIMZEY A'] # Data for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3710 entries, 0 to 4148\n",
      "Data columns (total 13 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   Facies         3710 non-null   int64   \n",
      " 1   Formation      3710 non-null   object  \n",
      " 2   Well Name      3710 non-null   category\n",
      " 3   Depth          3710 non-null   float64 \n",
      " 4   GR             3710 non-null   float64 \n",
      " 5   ILD_log10      3710 non-null   float64 \n",
      " 6   DeltaPHI       3710 non-null   float64 \n",
      " 7   PHIND          3710 non-null   float64 \n",
      " 8   PE             3710 non-null   float64 \n",
      " 9   NM_M           3710 non-null   int64   \n",
      " 10  RELPOS         3710 non-null   float64 \n",
      " 11  FaciesLabels   3710 non-null   object  \n",
      " 12  Formation_num  3710 non-null   int64   \n",
      "dtypes: category(1), float64(7), int64(3), object(2)\n",
      "memory usage: 380.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data_fe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see the impact of feature engineering we should build a baseline model to assist this task. Then, we can compare the baseline results with the ones from ML models with feature engineering.\n",
    "\n",
    "# Baseline model\n",
    "The baseline model should be a linear ML method (for regression is a linear regression and for classification is a logistic regression). This baseline model is built **without** feature extration or similar kind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into X and Y\n",
    "X = data_fe[['Depth', 'GR', 'ILD_log10','DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS', 'Formation_num']]\n",
    "y = data_fe['Facies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn Log_reg\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LOG = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "Obviously, we will implement the model with cross validation and examine its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.573\n"
     ]
    }
   ],
   "source": [
    "model = LOG\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "We can say the following:\n",
    " - Now we can compare the feature engineering step, and explore feautre extraction for improving the model `Accuracy`.\n",
    " - Other metrics can be used instead the `Accuracy`\n",
    " - There are many approaches while we will use some transforms for chaining the distribution of the input variables such as Quantile Transformer and KBins Discretizer. Then, will remove linear dependencies between the input variables using PCA and TruncatedSVD.\n",
    " - We will use the `sklearn.Pipeline` to define a list of transforms to perform the feature extraction. This will create a dataset with lots of feature columns while we need to reduce dimensionality to faster and better performance. Finally, Recursive Feature Elimination, or RFE, technique can be used to select the most relevant features. We select 30 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build pipeline \n",
    "We can use the baseline model together with **imputers** and **transformers** for feature extraction that perform feature engineering, before moving to more advance ML methods. Here, we will build a pipeline with different transformers to see how well they perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.614\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary classes from sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Build the transformers\n",
    "transforms = list()\n",
    "transforms.append(('qt', QuantileTransformer(n_quantiles=100, output_distribution='normal')))\n",
    "transforms.append(('kbd', KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')))\n",
    "transforms.append(('pca', PCA(n_components=7)))\n",
    "transforms.append(('svd', TruncatedSVD(n_components=7)))\n",
    "# Wrapper the transformrs\n",
    "featurizer = FeatureUnion(transforms)\n",
    "# Define the feature selection\n",
    "rfe = RFE(estimator=LogisticRegression(solver='liblinear'), n_features_to_select=30)\n",
    "# Model creation\n",
    "model = LOG\n",
    "\n",
    "# Pipeline to build the sequence (as steps)\n",
    "steps = list() # Attach all steps in sequence\n",
    "steps.append(('fu', featurizer))\n",
    "steps.append(('rfe', rfe))\n",
    "steps.append(('ml', model))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1) # Cross validation for the training\n",
    "\n",
    "# Training model\n",
    "scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# Print average score\n",
    "print('Accuracy: %.3f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    " - Improved `Accuracy` in 0.04 absolute value which is good for the model\n",
    " - Accuracy improvement shows that feature engineering can be useful approach when we are dealing with limited features in dataset\n",
    " - Avoiding as well the implementation of complex models with this simple engineering skill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance with imbalance datasets\n",
    "We are dealing with imbalance dataset where some classes have few datapoints, and this can affect the `Accuracy` of the method. In imbalanced datasets, we can use the resampling technique to add some more data points to increase members of minority groups. This can be helpful whenever minority label targets have special importance such as credit card or payment fraud detection (with typical less than 0.1 percent of fraud). For that, we can use **SMOTE** that is a very popular technique for oversampling the *minority* class (or classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE:  Counter({2: 855, 3: 706, 8: 596, 6: 531, 1: 259, 5: 243, 4: 228, 9: 178, 7: 114})\n",
      "After SMOTE:  Counter({3: 855, 2: 855, 8: 855, 6: 855, 7: 855, 4: 855, 5: 855, 9: 855, 1: 855})\n"
     ]
    }
   ],
   "source": [
    "# Import the SMOTE technique\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "X_sm1 , y_sm1 = smote.fit_resample(X,y)\n",
    "X_sm , y_sm = X_sm1 , y_sm1  # keep for future plotting an comparison\n",
    "\n",
    "print(\"Before SMOTE: \", Counter(y))\n",
    "print(\"After SMOTE: \", Counter(y_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all 9 classes completely (and equally) balanced. It is worthy to investigate the results of the baseline model (without feature engineering) with this balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.613\n"
     ]
    }
   ],
   "source": [
    "# Transform the data to Standard distribution (mu=0 and std=1)\n",
    "scaler = StandardScaler()\n",
    "X_sm = scaler.fit_transform(X_sm)\n",
    "\n",
    "# Re-run the baseline model with the balanced dataset\n",
    "scores = cross_val_score(model, X_sm, y_sm, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model reached the (almost) same `Accuracy` as the model before using the `pipeline` with preprocessors and transformers. We could even test the **SMOTE** with feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.640\n"
     ]
    }
   ],
   "source": [
    "# Re-run the pipeline with the feature extraction\n",
    "scores = cross_val_score(pipeline, X_sm, y_sm, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "print('Accuracy: %.3f' % (scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, `Accuracy` increases 0.03% but in multi-class classification, `Accuracy` is not the best evaluation metrics. We will cover others in next parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Feat eng dataset\n",
    "Let us save the balanced dataset with **SMOTE** since it presents good results in terms of `Accuracy`. We will use for later implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X_sm, y_sm to dataframes\n",
    "x_sm_df = pd.DataFrame(X_sm, columns=['Depth', 'GR', 'ILD_log10','DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS', 'Formation_num'])\n",
    "y_sm_df = pd.DataFrame(y_sm, columns=['Facies'])\n",
    "# Merge the X, y\n",
    "data_sm = pd.concat([x_sm_df, y_sm_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save on parquet file (spark format)\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Convert DataFrame to Apache Arrow Table\n",
    "data_pq = pa.Table.from_pandas(data_sm)\n",
    "# Parquet with Brotli compression\n",
    "pq.write_table(data_pq, 'facies_dataset_SMOTE.parquet')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d496e7e89a4953a2887635356beeeee15f779729450bc67379ba02863857a922"
  },
  "kernelspec": {
   "display_name": "sklearn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
